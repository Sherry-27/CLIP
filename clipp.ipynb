{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# CELL 1: Check GPU\n!nvidia-smi","metadata":{"id":"HvOQWwrx_dg_","outputId":"d5f83075-8a3d-4507-de33-a076b0a49185","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T13:49:09.746552Z","iopub.execute_input":"2026-02-15T13:49:09.746846Z","iopub.status.idle":"2026-02-15T13:49:09.913029Z","shell.execute_reply.started":"2026-02-15T13:49:09.746823Z","shell.execute_reply":"2026-02-15T13:49:09.912165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 2: Install Dependencies\nprint(\"ðŸ“¦ Installing dependencies...\")\n!pip install -q ftfy regex tqdm\n!pip install -q git+https://github.com/openai/CLIP.git\n!pip install -q faiss-gpu-cu12\n!pip install -q pillow\n!pip install -q matplotlib\n!pip install -q requests pandas\nprint(\"âœ… All dependencies installed!\")","metadata":{"id":"3UOgxoeVBDh-","outputId":"e623ff83-aa34-4039-9070-a30ad5af3289","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T13:49:09.915156Z","iopub.execute_input":"2026-02-15T13:49:09.915424Z","iopub.status.idle":"2026-02-15T13:49:39.707905Z","shell.execute_reply.started":"2026-02-15T13:49:09.915396Z","shell.execute_reply":"2026-02-15T13:49:39.706932Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 3: Import Libraries\nimport torch\nimport clip\nimport faiss\nimport numpy as np\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nimport os\nimport pickle\nimport json\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom typing import List, Tuple\nimport time\nimport pandas as pd\n\nprint(\"âœ… Libraries imported\")\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")","metadata":{"id":"KWTQsegQBgDz","outputId":"e2320dce-b772-4bb3-c165-4eb6b9d22640","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T13:49:39.709371Z","iopub.execute_input":"2026-02-15T13:49:39.709723Z","iopub.status.idle":"2026-02-15T13:49:47.052159Z","shell.execute_reply.started":"2026-02-15T13:49:39.709693Z","shell.execute_reply":"2026-02-15T13:49:47.051534Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 4: Load CLIP Model\nprint(\"\\nðŸš€ Loading CLIP model...\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel, preprocess = clip.load(\"ViT-B/32\", device=device)\nprint(f\"âœ… CLIP model loaded on {device}\")\nprint(f\"Model: ViT-B/32\")\nprint(f\"Input resolution: 224x224\")","metadata":{"id":"M84tt-I1BvZS","outputId":"a9428e88-71d7-4b09-e04f-b62a8de5d5c7","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T13:49:47.053042Z","iopub.execute_input":"2026-02-15T13:49:47.053447Z","iopub.status.idle":"2026-02-15T13:49:52.473489Z","shell.execute_reply.started":"2026-02-15T13:49:47.053422Z","shell.execute_reply":"2026-02-15T13:49:52.472711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\n# Define your image directory right here\nIMAGE_DIR = \"/kaggle/working/images/all\"\n\n# Create the folder\nos.makedirs(IMAGE_DIR, exist_ok=True)\n\nprint(f\"IMAGE_DIR is now: {IMAGE_DIR}\")\nprint(f\"Current working dir: {os.getcwd()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T13:49:52.474320Z","iopub.execute_input":"2026-02-15T13:49:52.474664Z","iopub.status.idle":"2026-02-15T13:49:52.479179Z","shell.execute_reply.started":"2026-02-15T13:49:52.474641Z","shell.execute_reply":"2026-02-15T13:49:52.478530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 5: Download Multiple Small Datasets\n\nprint(\"\\nðŸ“¥ Downloading multiple image datasets...\")\n\nimport os\nfrom pathlib import Path\n\n# â”€â”€ 1. COCO val2017 â”€â”€ (~5,000 images)\nprint(\"â†’ Downloading & extracting COCO val2017...\")\nos.makedirs(\"images/coco\", exist_ok=True)\n\n# Download if not already present\ncoco_zip = \"val2017.zip\"\nif not os.path.exists(coco_zip):\n    !wget -q http://images.cocodataset.org/zips/val2017.zip -O {coco_zip}\n\n# Extract with overwrite (non-interactive)\n!unzip -q -o {coco_zip} -d images/coco > /dev/null 2>&1\n\n# Clean up zip\nif os.path.exists(coco_zip):\n    os.remove(coco_zip)\n\ncoco_count = len(list(Path(\"images/coco/val2017\").glob(\"*.jpg\")))\nprint(f\"   â†’ COCO images extracted: {coco_count}\")\n\n# â”€â”€ 2. Flickr30k images â”€â”€ (reliable public mirror)\nprint(\"â†’ Downloading Flickr30k images (from awsaf49 GitHub mirror)...\")\nos.makedirs(\"images/flickr30k\", exist_ok=True)\n\n# Download the three split parts\nparts = [\n    \"flickr30k_part00\",\n    \"flickr30k_part01\",\n    \"flickr30k_part02\"\n]\n\nfor part in parts:\n    url = f\"https://github.com/awsaf49/flickr-dataset/releases/download/v1.0/{part}\"\n    !wget -q {url} -O {part}\n\n# Combine into one zip\n!cat {' '.join(parts)} > flickr30k.zip 2>/dev/null\n\n# Clean up parts\nfor part in parts:\n    if os.path.exists(part):\n        os.remove(part)\n\n# Extract non-interactively\nprint(\"   â†’ Extracting Flickr30k...\")\n!unzip -q -o flickr30k.zip -d flickr_temp > /dev/null 2>&1\n\n# Move images (some mirrors have different folder structure)\n!mkdir -p images/flickr30k\n!find flickr_temp -type f -name \"*.jpg\" -exec mv {} images/flickr30k/ \\; 2>/dev/null || true\n\n# Clean up temp files\n!rm -rf flickr_temp flickr30k.zip\n\n# Limit to first 9000 images (adjust as needed)\nflickr_paths = sorted(Path(\"images/flickr30k\").glob(\"*.jpg\"))\nflickr_selected = flickr_paths[:9000]\nflickr_count = len(flickr_selected)\nprint(f\"   â†’ Using {flickr_count} images from Flickr30k\")\n\n# â”€â”€ Create unified image directory â”€â”€\nprint(\"â†’ Creating unified image folder...\")\nos.makedirs(\"images/all\", exist_ok=True)\n\n# Copy COCO images (non-overwrite)\n!cp -n images/coco/val2017/*.jpg images/all/ 2>/dev/null || true\n\n# Copy selected Flickr30k images\nfor src in flickr_selected:\n    !cp -n \"{src}\" images/all/ 2>/dev/null || true\n\n# Final count\ntotal_images = len(list(Path(\"images/all\").glob(\"*.jpg\")))\nprint(f\"Total images ready for encoding: {total_images}\")\nprint(f\"   â†’ Directory: images/all\")","metadata":{"id":"InotxiPbCO-g","outputId":"11d8f00c-6df9-414b-db1c-7d3820535b96","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T13:49:52.480934Z","iopub.execute_input":"2026-02-15T13:49:52.481164Z","iopub.status.idle":"2026-02-15T14:17:26.133235Z","shell.execute_reply.started":"2026-02-15T13:49:52.481130Z","shell.execute_reply":"2026-02-15T14:17:26.132427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Your path fixing code â€“ now IMAGE_DIR is defined\nbase_dir = os.path.abspath(IMAGE_DIR)\n\nfixed_paths = []\nmissing_count = 0\n\nprint(\"Fixing image paths...\")\nfor old_path in search_engine.image_paths:\n    filename = os.path.basename(old_path)\n    new_path = os.path.join(base_dir, filename)\n    if os.path.exists(new_path):\n        fixed_paths.append(new_path)\n    else:\n        fixed_paths.append(None)\n        missing_count += 1\n        print(f\"Still missing: {filename}\")\n\nsearch_engine.image_paths = fixed_paths\n\nprint(f\"Path fix complete.\")\nprint(f\"Total images in index: {len(search_engine.image_paths)}\")\nprint(f\"Still missing files: {missing_count}\")\nif search_engine.image_paths:\n    print(f\"Example fixed path: {search_engine.image_paths[0]}\")\nelse:\n    print(\"No paths fixed â€“ check if search_engine.image_paths was empty\")","metadata":{"id":"wREvR5ZhTd0Y","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:17:26.543514Z","iopub.execute_input":"2026-02-15T14:17:26.544036Z","iopub.status.idle":"2026-02-15T14:17:26.552982Z","shell.execute_reply.started":"2026-02-15T14:17:26.544003Z","shell.execute_reply":"2026-02-15T14:17:26.552120Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 6: CLIPImageSearch Class (same as before)\n\nclass CLIPImageSearch:\n    def __init__(self, model, preprocess, device):\n        self.model = model\n        self.preprocess = preprocess\n        self.device = device\n        self.image_paths = []\n        self.image_features = None\n        self.index = None\n        self.dimension = 512\n\n    def encode_images(self, image_dir: str, batch_size: int = 32):\n        image_extensions = {'.jpg', '.jpeg', '.png'}\n        image_files = []\n        for ext in image_extensions:\n            image_files.extend(Path(image_dir).glob(f'*{ext}'))\n\n        self.image_paths = [str(p) for p in sorted(image_files)]\n        print(f\"ðŸ“ Found {len(self.image_paths)} images\")\n\n        if len(self.image_paths) == 0:\n            print(\"âŒ No images found!\")\n            return\n\n        all_features = []\n        for i in tqdm(range(0, len(self.image_paths), batch_size), desc=\"Encoding images\"):\n            batch_paths = self.image_paths[i:i+batch_size]\n            batch_images = []\n            for img_path in batch_paths:\n                try:\n                    image = Image.open(img_path).convert('RGB')\n                    image = self.preprocess(image)\n                    batch_images.append(image)\n                except:\n                    continue\n\n            if not batch_images:\n                continue\n\n            batch_tensor = torch.stack(batch_images).to(self.device)\n            with torch.no_grad():\n                features = self.model.encode_image(batch_tensor)\n                features = features / features.norm(dim=-1, keepdim=True)\n            all_features.append(features.cpu().numpy())\n\n        if all_features:\n            self.image_features = np.vstack(all_features)\n            print(f\"âœ… Encoded {len(self.image_features)} images\")\n        else:\n            print(\"âŒ Encoding failed\")\n\n    def build_index(self, index_type='flatip'):\n        if self.image_features is None:\n            print(\"âŒ No features! Run encode_images first.\")\n            return\n\n        print(f\"Building FAISS index ({index_type})...\")\n\n        if index_type == 'flatl2':\n            self.index = faiss.IndexFlatL2(self.dimension)\n        elif index_type == 'flatip':\n            self.index = faiss.IndexFlatIP(self.dimension)\n        elif index_type == 'ivf':\n            nlist = 100\n            quantizer = faiss.IndexFlatL2(self.dimension)\n            self.index = faiss.IndexIVFFlat(quantizer, self.dimension, nlist)\n            self.index.train(self.image_features)\n\n        self.index.add(self.image_features.astype('float32'))\n        print(f\"âœ… Index built â€” {self.index.ntotal} vectors\")\n\n    def search_by_text(self, query: str, top_k: int = 10) -> List[Tuple[str, float]]:\n        text_tokens = clip.tokenize([query]).to(self.device)\n        with torch.no_grad():\n            text_features = self.model.encode_text(text_tokens)\n            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n        text_features = text_features.cpu().numpy().astype('float32')\n\n        distances, indices = self.index.search(text_features, top_k)\n\n        results = []\n        for idx, dist in zip(indices[0], distances[0]):\n            if idx < len(self.image_paths):\n                results.append((self.image_paths[idx], float(dist)))\n        return results\n\n    def save_index(self, save_dir: str):\n        os.makedirs(save_dir, exist_ok=True)\n        faiss.write_index(self.index, os.path.join(save_dir, 'image_index.faiss'))\n        metadata = {\n            'image_paths': self.image_paths,\n            'num_images': len(self.image_paths),\n            'dimension': self.dimension\n        }\n        with open(os.path.join(save_dir, 'metadata.json'), 'w') as f:\n            json.dump(metadata, f, indent=2)\n        np.save(os.path.join(save_dir, 'image_features.npy'), self.image_features)\n        print(f\"Index saved â†’ {save_dir}\")\n\nprint(\"âœ… CLIPImageSearch class ready\")","metadata":{"id":"WFYltaeGCSW4","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:17:26.665061Z","iopub.execute_input":"2026-02-15T14:17:26.665405Z","iopub.status.idle":"2026-02-15T14:17:26.682111Z","shell.execute_reply.started":"2026-02-15T14:17:26.665375Z","shell.execute_reply":"2026-02-15T14:17:26.681242Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 7: Build & Save Index\n\nsearch_engine = CLIPImageSearch(model, preprocess, device)\n\nprint(\"\\nEncoding images (this will take several minutes)...\")\nsearch_engine.encode_images(IMAGE_DIR, batch_size=48)   # adjust batch size according to GPU memory\n\nprint(\"\\nBuilding index...\")\nsearch_engine.build_index(index_type='flatip')          # cosine similarity\n\nprint(\"\\nSaving index...\")\nsearch_engine.save_index('clip_index_small')","metadata":{"id":"z3l4XJivRtu1","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:17:26.730279Z","iopub.execute_input":"2026-02-15T14:17:26.730517Z","iopub.status.idle":"2026-02-15T14:19:20.366150Z","shell.execute_reply.started":"2026-02-15T14:17:26.730496Z","shell.execute_reply":"2026-02-15T14:19:20.365353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# CELL 8: Quick Test â€“ Text Search\n\ntest_queries = [\n    \"a cute dog running in the park\",\n    \"person riding a bicycle\",\n    \"beautiful mountain landscape\",\n    \"plate of delicious food\",\n    \"woman wearing red dress\"\n]\n\nfor query in test_queries:\n    print(f\"\\nQuery: {query}\")\n    results = search_engine.search_by_text(query, top_k=5)\n    for i, (path, score) in enumerate(results, 1):\n        print(f\"  {i}. {os.path.basename(path)}  â†’ score {score:.4f}\")","metadata":{"id":"2L-_br94Rwxw","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:19:20.367464Z","iopub.execute_input":"2026-02-15T14:19:20.367699Z","iopub.status.idle":"2026-02-15T14:19:20.517851Z","shell.execute_reply.started":"2026-02-15T14:19:20.367677Z","shell.execute_reply":"2026-02-15T14:19:20.517277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_top_results(query, results, ncols=5):\n    print(f\"\\nQuery: {query}\")\n    plt.figure(figsize=(15, 4))\n    displayed = 0\n    for fname, score in results:\n        # Use basename only, combine with current IMAGE_DIR\n        img_path = os.path.join(IMAGE_DIR, os.path.basename(fname))\n        if os.path.exists(img_path):\n            img = Image.open(img_path)\n            plt.subplot(1, ncols, displayed + 1)\n            plt.imshow(img)\n            plt.title(f\"{score:.4f}\")\n            plt.axis('off')\n            displayed += 1\n        else:\n            print(f\"Missing image: {os.path.basename(fname)}\")\n    if displayed == 0:\n        print(\"No images found for display\")\n    plt.suptitle(query, fontsize=14)\n    plt.tight_layout()\n    plt.show()\n\n# Test again\nfor q in [\n    \"a cute dog running in the park\",\n    \"person riding a bicycle\",\n    \"plate of delicious food\"\n]:\n    results = search_engine.search_by_text(q, top_k=5)\n    show_top_results(q, results)","metadata":{"id":"2xFFf-21TNkF","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:19:20.518630Z","iopub.execute_input":"2026-02-15T14:19:20.518896Z","iopub.status.idle":"2026-02-15T14:19:21.867357Z","shell.execute_reply.started":"2026-02-15T14:19:20.518860Z","shell.execute_reply":"2026-02-15T14:19:21.866578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save (or re-save) the index\nsearch_engine.save_index(\"clip_search_index\")\n\n# Optional: create a folder structure that's easier to upload\n!mkdir -p hf_space_files\n!cp -r clip_search_index hf_space_files/\n!cp -r images/all hf_space_files/images   # or only a subset if too big","metadata":{"id":"spRIw7yTUIRt","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:19:21.869420Z","iopub.execute_input":"2026-02-15T14:19:21.869737Z","iopub.status.idle":"2026-02-15T14:19:24.185788Z","shell.execute_reply.started":"2026-02-15T14:19:21.869704Z","shell.execute_reply":"2026-02-15T14:19:24.184749Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\n\n# Load existing metadata\nwith open(\"clip_search_index/metadata.json\", \"r\") as f:\n    metadata = json.load(f)\n\n# Convert to filenames only\nmetadata[\"image_paths\"] = [os.path.basename(p) for p in metadata[\"image_paths\"]]\n\n# Optional: also save num_images\nmetadata[\"num_images\"] = len(metadata[\"image_paths\"])\n\n# Save updated version\nwith open(\"clip_search_index/metadata_clean.json\", \"w\") as f:\n    json.dump(metadata, f, indent=2)\n\nprint(\"Saved metadata with filenames only\")\nprint(f\"Number of images referenced: {metadata['num_images']}\")","metadata":{"id":"XLalwLGKVEPu","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:19:24.187068Z","iopub.execute_input":"2026-02-15T14:19:24.187900Z","iopub.status.idle":"2026-02-15T14:19:24.205978Z","shell.execute_reply.started":"2026-02-15T14:19:24.187867Z","shell.execute_reply":"2026-02-15T14:19:24.205325Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport shutil\n\nsubset_dir = \"hf_space_files/images_subset\"\nos.makedirs(subset_dir, exist_ok=True)\n\nall_images = list(Path(\"images/all\").glob(\"*.jpg\"))\nselected = random.sample(all_images, min(500, len(all_images)))\n\nfor img_path in selected:\n    shutil.copy(img_path, subset_dir)\n\nprint(f\"Copied {len(selected)} images to images_subset/\")","metadata":{"id":"4FQWTXp5WJIT","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:19:24.207507Z","iopub.execute_input":"2026-02-15T14:19:24.207885Z","iopub.status.idle":"2026-02-15T14:19:24.343809Z","shell.execute_reply.started":"2026-02-15T14:19:24.207853Z","shell.execute_reply":"2026-02-15T14:19:24.343260Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U huggingface_hub\n\nfrom huggingface_hub import login\n\n# Run this cell and follow the link to authenticate\nlogin()   # â† paste your Hugging Face access token here","metadata":{"id":"5eCf799XWWgh","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:19:24.344772Z","iopub.execute_input":"2026-02-15T14:19:24.345401Z","iopub.status.idle":"2026-02-15T14:19:29.142463Z","shell.execute_reply.started":"2026-02-15T14:19:24.345377Z","shell.execute_reply":"2026-02-15T14:19:29.141687Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi\nimport os\nfrom pathlib import Path\nimport random\nimport shutil\n\n# ==============================================\n# CONFIG - change these if needed\n# ==============================================\nSPACE_ID = \"Shaheerkhan/clip-faiss-image-search\"   # your space\nLOCAL_IMAGE_FOLDER = \"images/all\"                   # where your full images are\nNUMBER_OF_IMAGES_TO_UPLOAD = 300                    # change this (100â€“800 is reasonable)\nPATH_IN_SPACE = \"images\"                            # folder name in the space\n\n# ==============================================\n# Prepare temporary folder for upload\n# ==============================================\ntemp_upload_dir = \"temp_images_upload\"\nos.makedirs(temp_upload_dir, exist_ok=True)\n\n# Get all images\nall_images = list(Path(LOCAL_IMAGE_FOLDER).glob(\"*.jpg\"))\n\nif not all_images:\n    print(\"Error: No images found in\", LOCAL_IMAGE_FOLDER)\nelse:\n    print(f\"Found {len(all_images)} images total\")\n\n    # Select random subset\n    selected_images = random.sample(all_images, min(NUMBER_OF_IMAGES_TO_UPLOAD, len(all_images)))\n    print(f\"Selected {len(selected_images)} images to upload\")\n\n    # Copy to temp folder\n    for img_path in selected_images:\n        shutil.copy(img_path, temp_upload_dir)\n\n    print(\"Temporary folder prepared:\", temp_upload_dir)\n\n    # Show first few files (fixed version)\n    files = list(Path(temp_upload_dir).glob(\"*\"))\n    if files:\n        print(\"First few files:\", [f.name for f in files[:5]])\n    else:\n        print(\"No files were copied â€“ check if source images exist\")\n\n    # ==============================================\n    # Upload to Hugging Face Space\n    # ==============================================\n    api = HfApi()\n\n    print(f\"\\nUploading {len(selected_images)} images to {SPACE_ID}/{PATH_IN_SPACE}/ ...\")\n\n    api.upload_folder(\n        folder_path=temp_upload_dir,\n        repo_id=SPACE_ID,\n        repo_type=\"space\",\n        path_in_repo=PATH_IN_SPACE,           # creates images/ folder if needed\n        commit_message=f\"Add {len(selected_images)} demo images\",\n        ignore_patterns=[\"*.tmp\", \"__pycache__\"]\n    )\n\n    print(\"\\nUpload finished!\")\n    print(f\"Images should now appear in: https://huggingface.co/spaces/{SPACE_ID}/tree/main/{PATH_IN_SPACE}\")","metadata":{"id":"XGyNLKu-X8nA","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:31.377572Z","iopub.execute_input":"2026-02-15T14:25:31.377900Z","iopub.status.idle":"2026-02-15T14:25:53.940746Z","shell.execute_reply.started":"2026-02-15T14:25:31.377871Z","shell.execute_reply":"2026-02-15T14:25:53.939406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\nfrom pathlib import Path\n\n# Point to your local images folder\nimage_folder = \"images/all\"   # or wherever your full set is\n\n# Get all .jpg filenames\nimage_files = [f.name for f in Path(image_folder).glob(\"*.jpg\")]\n\n# Create metadata structure (filenames only)\nmetadata = {\n    \"image_paths\": image_files,          # just names like \"000000123456.jpg\"\n    \"num_images\": len(image_files),\n    \"dimension\": 512                     # CLIP ViT-B/32 dimension\n}\n\n# Save it locally\nos.makedirs(\"clip_search_index\", exist_ok=True)\nwith open(\"clip_search_index/metadata.json\", \"w\") as f:\n    json.dump(metadata, f, indent=2)\n\nprint(f\"Created metadata.json with {len(image_files)} filenames\")\nprint(\"First few filenames:\", image_files[:5])","metadata":{"id":"ZpB_MF6jYsfq","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:53.941297Z","iopub.status.idle":"2026-02-15T14:25:53.941582Z","shell.execute_reply.started":"2026-02-15T14:25:53.941438Z","shell.execute_reply":"2026-02-15T14:25:53.941457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi()\n\napi.upload_file(\n    path_or_fileobj=\"clip_search_index/metadata.json\",\n    path_in_repo=\"clip_search_index/metadata.json\",\n    repo_id=\"Shaheerkhan/clip-faiss-image-search\",\n    repo_type=\"space\",\n    commit_message=\"Add missing metadata.json\"\n)","metadata":{"id":"6WQ3brL7cs5d","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:53.942651Z","iopub.status.idle":"2026-02-15T14:25:53.943002Z","shell.execute_reply.started":"2026-02-15T14:25:53.942817Z","shell.execute_reply":"2026-02-15T14:25:53.942840Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"api.upload_folder(\n    folder_path=\"clip_search_index\",               # folder with metadata.json + image_index.faiss\n    repo_id=\"Shaheerkhan/clip-faiss-image-search\",\n    repo_type=\"space\",\n    path_in_repo=\"clip_search_index\",\n    commit_message=\"Add FAISS index and metadata\"\n)","metadata":{"id":"CLF6AmNcc16L","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:53.944268Z","iopub.status.idle":"2026-02-15T14:25:53.944636Z","shell.execute_reply.started":"2026-02-15T14:25:53.944470Z","shell.execute_reply":"2026-02-15T14:25:53.944491Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Re-run these lines (adjust if your variable name is different)\nsearch_engine.build_index(index_type='flatip')\nsearch_engine.save_index('clip_search_index')","metadata":{"id":"uQZCRNYwdAVh","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:53.945581Z","iopub.status.idle":"2026-02-15T14:25:53.945828Z","shell.execute_reply.started":"2026-02-15T14:25:53.945712Z","shell.execute_reply":"2026-02-15T14:25:53.945727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh clip_search_index/","metadata":{"id":"ggnCABUsinbY","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:53.947548Z","iopub.status.idle":"2026-02-15T14:25:53.947906Z","shell.execute_reply.started":"2026-02-15T14:25:53.947730Z","shell.execute_reply":"2026-02-15T14:25:53.947753Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi()\n\n# Upload FAISS index\napi.upload_file(\n    path_or_fileobj=\"clip_search_index/image_index.faiss\",\n    path_in_repo=\"clip_search_index/image_index.faiss\",\n    repo_id=\"Shaheerkhan/clip-faiss-image-search\",\n    repo_type=\"space\",\n    commit_message=\"Add missing image_index.faiss\"\n)\n\n# Re-upload metadata.json (to make sure it's fresh)\napi.upload_file(\n    path_or_fileobj=\"clip_search_index/metadata.json\",\n    path_in_repo=\"clip_search_index/metadata.json\",\n    repo_id=\"Shaheerkhan/clip-faiss-image-search\",\n    repo_type=\"space\",\n    commit_message=\"Update metadata.json\"\n)\n\nprint(\"Upload complete! Wait 2â€“5 minutes then refresh Space.\")","metadata":{"id":"84zP-zezj9z0","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:53.948588Z","iopub.status.idle":"2026-02-15T14:25:53.948866Z","shell.execute_reply.started":"2026-02-15T14:25:53.948722Z","shell.execute_reply":"2026-02-15T14:25:53.948740Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ls -lh clip_search_index/\n!du -sh clip_search_index/image_index.faiss 2>/dev/null || echo \"image_index.faiss not found!\"","metadata":{"id":"qrkBfgMUkBmL","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:53.949461Z","iopub.status.idle":"2026-02-15T14:25:53.950548Z","shell.execute_reply.started":"2026-02-15T14:25:53.950400Z","shell.execute_reply":"2026-02-15T14:25:53.950425Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport clip\nfrom pathlib import Path\nfrom PIL import Image\nimport numpy as np\nfrom tqdm import tqdm\nimport faiss\nimport os\nimport json\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"Using device: {device}\")\n\nmodel, preprocess = clip.load(\"ViT-B/32\", device=device)\n\nclass CLIPImageSearch:\n    def __init__(self, model, preprocess, device):\n        self.model = model\n        self.preprocess = preprocess\n        self.device = device\n        self.image_paths = []\n        self.image_features = None\n        self.index = None\n        self.dimension = 512\n\n    def encode_images(self, image_dir, batch_size=16):\n        files = list(Path(image_dir).glob(\"*.jpg\"))\n        if not files:\n            print(\"No images found in\", image_dir)\n            return\n\n        self.image_paths = [str(p) for p in files]\n        print(f\"Found {len(self.image_paths)} images\")\n\n        features_list = []\n        for start in tqdm(range(0, len(files), batch_size)):\n            batch_paths = files[start:start+batch_size]\n            batch_imgs = []\n            for p in batch_paths:\n                try:\n                    img = Image.open(p).convert(\"RGB\")\n                    batch_imgs.append(self.preprocess(img))\n                except Exception as e:\n                    print(f\"Skip {p}: {e}\")\n            if not batch_imgs:\n                continue\n            tensor = torch.stack(batch_imgs).to(self.device)\n            with torch.no_grad():\n                emb = self.model.encode_image(tensor)\n                emb = emb / emb.norm(dim=-1, keepdim=True)\n            features_list.append(emb.cpu().numpy())\n\n        if features_list:\n            self.image_features = np.concatenate(features_list)\n            print(f\"Encoded {len(self.image_features)} features successfully\")\n        else:\n            print(\"No features encoded - check image loading\")\n\n    def build_index(self):\n        if self.image_features is None or len(self.image_features) == 0:\n            print(\"No features to index!\")\n            return\n        self.index = faiss.IndexFlatIP(self.dimension)\n        self.index.add(self.image_features.astype('float32'))\n        print(f\"Index built with {self.index.ntotal} vectors\")\n\n    def save_index(self, save_dir):\n        os.makedirs(save_dir, exist_ok=True)\n        if self.index is not None:\n            faiss.write_index(self.index, os.path.join(save_dir, \"image_index.faiss\"))\n        metadata = {\n            \"image_paths\": self.image_paths,\n            \"num_images\": len(self.image_paths),\n            \"dimension\": self.dimension\n        }\n        with open(os.path.join(save_dir, \"metadata.json\"), \"w\") as f:\n            json.dump(metadata, f, indent=2)\n        print(f\"Saved to {save_dir}\")\n        !ls -lh {save_dir}\n\nprint(\"Class ready\")","metadata":{"id":"m8i73NxAkpnZ","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:53.951339Z","iopub.status.idle":"2026-02-15T14:25:53.951672Z","shell.execute_reply.started":"2026-02-15T14:25:53.951483Z","shell.execute_reply":"2026-02-15T14:25:53.951505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"search_engine = CLIPImageSearch(model, preprocess, device)\n\n# Use the subset you uploaded or full folder\n# Change path if needed\nsearch_engine.encode_images(\"temp_images_upload\", batch_size=16)  # or \"images/all\"","metadata":{"id":"s4yCxtdok7-P","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:53.952878Z","iopub.status.idle":"2026-02-15T14:25:53.953234Z","shell.execute_reply.started":"2026-02-15T14:25:53.953070Z","shell.execute_reply":"2026-02-15T14:25:53.953091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\n\npossible_dirs = [\n    \"images/all\",\n    \"images\",\n    \"temp_images_upload\",\n    \"hf_space_files/images_subset\",\n    \"Images\",\n    \"images/coco/val2017\",\n    \"images/flickr30k\",\n    \"images/unsplash\"\n]\n\nfor d in possible_dirs:\n    if Path(d).exists():\n        jpg_count = len(list(Path(d).glob(\"*.jpg\")))\n        print(f\"Folder '{d}': {jpg_count} .jpg files\")\n    else:\n        print(f\"Folder '{d}': does NOT exist\")","metadata":{"id":"1PeEL_GvlBvO","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:53.954634Z","iopub.status.idle":"2026-02-15T14:25:53.954885Z","shell.execute_reply.started":"2026-02-15T14:25:53.954769Z","shell.execute_reply":"2026-02-15T14:25:53.954784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi()\n\napi.upload_file(\n    path_or_fileobj=\"clip_search_index/image_index.faiss\",\n    path_in_repo=\"clip_search_index/image_index.faiss\",\n    repo_id=\"Shaheerkhan/clip-faiss-image-search\",\n    repo_type=\"space\",\n    commit_message=\"Upload missing image_index.faiss\"\n)","metadata":{"id":"KH721SjwlToA","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:54.301829Z","iopub.execute_input":"2026-02-15T14:25:54.302417Z","iopub.status.idle":"2026-02-15T14:25:55.972259Z","shell.execute_reply.started":"2026-02-15T14:25:54.302384Z","shell.execute_reply":"2026-02-15T14:25:55.971614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi()\n\n# Upload the real FAISS index (this is the important one)\napi.upload_file(\n    path_or_fileobj=\"clip_search_index/image_index.faiss\",\n    path_in_repo=\"clip_search_index/image_index.faiss\",\n    repo_id=\"Shaheerkhan/clip-faiss-image-search\",\n    repo_type=\"space\",\n    commit_message=\"Upload real 28MB FAISS index after successful encoding\"\n)\n\n# Re-upload metadata.json to make sure it's fresh\napi.upload_file(\n    path_or_fileobj=\"clip_search_index/metadata.json\",\n    path_in_repo=\"clip_search_index/metadata.json\",\n    repo_id=\"Shaheerkhan/clip-faiss-image-search\",\n    repo_type=\"space\",\n    commit_message=\"Update metadata.json with real filenames\"\n)\n\nprint(\"Upload finished! Wait 3â€“5 minutes for Space to rebuild.\")","metadata":{"id":"VwqaNlH9l806","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:25:55.973525Z","iopub.execute_input":"2026-02-15T14:25:55.973781Z","iopub.status.idle":"2026-02-15T14:26:00.662178Z","shell.execute_reply.started":"2026-02-15T14:25:55.973759Z","shell.execute_reply":"2026-02-15T14:26:00.661523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\n\n# If you have the subset folder with uploaded images\nsubset_folder = \"temp_images_upload\"  # change to your real folder if different\n\nfilenames = [f.name for f in Path(subset_folder).glob(\"*.jpg\")]\n\nif not filenames:\n    # Fallback: use first 300 real filenames you know from the Space page\n    filenames = [\n        \"000000001268.jpg\",\n        \"000000001353.jpg\",\n        \"000000001503.jpg\",\n        \"000000005529.jpg\",\n        # ... add more from your uploaded list (copy from browser)\n        # or leave as is for testing\n    ] * 3  # repeat to reach ~300\n\nmetadata = {\n    \"image_paths\": filenames[:300],  # limit to uploaded count\n    \"num_images\": len(filenames[:300]),\n    \"dimension\": 512\n}\n\nwith open(\"clip_search_index/metadata.json\", \"w\") as f:\n    json.dump(metadata, f, indent=2)\n\nprint(f\"Created metadata with {len(filenames[:300])} filenames\")\nprint(\"First 5:\", filenames[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:26:00.663045Z","iopub.execute_input":"2026-02-15T14:26:00.663343Z","iopub.status.idle":"2026-02-15T14:26:00.672406Z","shell.execute_reply.started":"2026-02-15T14:26:00.663319Z","shell.execute_reply":"2026-02-15T14:26:00.671725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\napi = HfApi()\n\napi.upload_file(\n    path_or_fileobj=\"clip_search_index/metadata.json\",\n    path_in_repo=\"clip_search_index/metadata.json\",\n    repo_id=\"Shaheerkhan/clip-faiss-image-search\",\n    repo_type=\"space\",\n    commit_message=\"Fix metadata.json to match uploaded Images filenames\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:26:00.673871Z","iopub.execute_input":"2026-02-15T14:26:00.674342Z","iopub.status.idle":"2026-02-15T14:26:01.754193Z","shell.execute_reply.started":"2026-02-15T14:26:00.674311Z","shell.execute_reply":"2026-02-15T14:26:01.753480Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example: paste the first 50â€“100 filenames from your browser\nreal_filenames = [\n    \"2321764238.jpg\",\n    \"1425013325.jpg\",\n    \"000000071226.jpg\",\n    \"2620756624.jpg\",\n    \"2312731013.jpg\",\n    \"000000119445.jpg\",\n    \"2769239715.jpg\",\n    \"1876536922.jpg\",\n    \"2339632913.jpg\",\n    \"11214470.jpg\",\n    \"2473689180.jpg\",\n    \"273056557.jpg\",\n    \"250343744.jpg\",\n    \"202440477.jpg\",\n    \"128396150.jpg\",\n    \"000000027696.jpg\",\n    \"137453678.jpg\",\n    \"000000412887.jpg\",\n    \"000000245915.jpg\",\n    \"116457850.jpg\",\n    \"2378149488.jpg\",\n    \"2724485630.jpg\",\n    \"2393911878.jpg\",\n    \"2438452274.jpg\",\n    \"1819261140.jpg\",\n    \"1456393634.jpg\",\n    \"1499554025.jpg\",\n    \"000000532530.jpg\",\n    \"2282522980.jpg\",\n    \"2494519396.jpg\",\n    \"000000311909.jpg\",\n    \"1357689954.jpg\",\n    \"109823397.jpg\",\n    \"2617215392.jpg\",\n    \"000000172617.jpg\",\n    \"1428641354.jpg\",\n    \"1386207171.jpg\",\n    \"2341245764.jpg\",\n    \"231935782.jpg\",\n    \"000000398377.jpg\",\n    \"2464118785.jpg\",\n    \"000000512776.jpg\",\n    \"2292235516.jpg\",\n    \"2554586230.jpg\",\n    \"000000519338.jpg\",\n    \"2525666287.jpg\",\n    \"2144459403.jpg\",\n    \"2066691122.jpg\",\n    \"2090601289.jpg\",\n    \"2084157130.jpg\",\n    \"000000103548.jpg\",\n    \"1386251841.jpg\",\n    \"2605279520.jpg\",\n    \"1105137588.jpg\",\n    \"000000238410.jpg\",\n    \"2684878115.jpg\",\n    \"153106887.jpg\",\n    \"000000019924.jpg\",\n    \"2453891449.jpg\",\n    \"000000186282.jpg\",\n    \"000000413247.jpg\",\n    \"000000579902.jpg\",\n    \"164380865.jpg\",\n    \"2213987357.jpg\",\n    \"2374382816.jpg\",\n    \"000000474786.jpg\",\n    \"000000081738.jpg\",\n    \"2156726763.jpg\",\n    \"2442662073.jpg\",\n    \"2773400732.jpg\",\n    \"2428797297.jpg\",\n    \"2584020755.jpg\",\n    \"1482654385.jpg\",\n    \"11079715.jpg\",\n    \"2291956529.jpg\",\n    \"000000471893.jpg\",\n    \"2648399206.jpg\",\n    \"000000084431.jpg\",\n    \"000000319607.jpg\",\n    \"2217328285.jpg\",\n    \"2446842020.jpg\",\n    \"000000355240.jpg\",\n    \"1480467399.jpg\",\n    \"000000527695.jpg\",\n    \"218854747.jpg\",\n    \"26690039.jpg\",\n    \"000000347693.jpg\",\n    \"000000491497.jpg\",\n    \"000000010707.jpg\",\n    \"1104133405.jpg\",\n    \"000000120572.jpg\",\n    \"000000400794.jpg\",\n    \"000000302030.jpg\",\n    \"134724228.jpg\",\n    \"2795866891.jpg\",\n    \"136886677.jpg\",\n    \"205149260.jpg\",\n    \"2582211817.jpg\",\n    \"2344412916.jpg\",\n    \"000000515025.jpg\",\n    \"2467850190.jpg\",\n    \"241347635.jpg\",\n    \"2474918824.jpg\",\n    \"000000000285.jpg\",\n    \"2705103507.jpg\",\n    \"224882899.jpg\",\n    \"2471447879.jpg\",\n    \"000000491130.jpg\",\n    \"215982386.jpg\",\n    \"000000173383.jpg\",\n    \"000000059386.jpg\",\n    \"2612027851.jpg\",\n    \"2635509973.jpg\",\n    \"000000115245.jpg\",\n    \"2437766095.jpg\",\n    \"000000578236.jpg\",\n    \"2460188548.jpg\",\n    \"236788203.jpg\",\n    \"159712188.jpg\",\n    \"2315464116.jpg\",\n    \"145721496.jpg\",\n    \"217593609.jpg\",\n    \"2680619645.jpg\",\n    \"000000107094.jpg\",\n    \"000000267434.jpg\",\n    \"1001465944.jpg\",\n    \"1341077576.jpg\",\n    \"000000397303.jpg\",\n    \"000000513567.jpg\",\n    \"23770160.jpg\",\n    \"000000190236.jpg\",\n    \"000000190648.jpg\",\n    \"000000551439.jpg\",\n    \"2565539201.jpg\",\n    \"000000533206.jpg\",\n    \"000000049759.jpg\",\n    \"160128865.jpg\",\n    \"2580503256.jpg\",\n    \"2697822530.jpg\",\n    \"000000078426.jpg\",\n    \"1386964743.jpg\",\n    \"2483792149.jpg\",\n    \"16158623.jpg\",\n    \"135911244.jpg\",\n    \"2431723485.jpg\",\n    \"2766325714.jpg\",\n    \"000000153797.jpg\",\n    \"218342358.jpg\",\n    \"2379795688.jpg\",\n    \"2036080069.jpg\",\n    \"264141937.jpg\",\n    \"000000087144.jpg\",\n    \"122868800.jpg\",\n    \"240583223.jpg\",\n    \"000000458325.jpg\",\n    \"000000504000.jpg\",\n    \"2500354186.jpg\",\n    \"1303573561.jpg\",\n    \"2533076864.jpg\",\n    \"2705793985.jpg\",\n    \"241346971.jpg\",\n    \"000000084650.jpg\",\n    \"000000320642.jpg\",\n    \"2638369467.jpg\",\n    \"2172574039.jpg\",\n    \"12393802.jpg\",\n    \"2743046728.jpg\",\n    \"000000160666.jpg\",\n    \"2252311564.jpg\",\n    \"000000121744.jpg\",\n    \"2215875786.jpg\",\n    \"000000378515.jpg\",\n    \"000000446117.jpg\",\n    \"1083240835.jpg\",\n    \"2605495015.jpg\",\n    \"1679557684.jpg\",\n    \"133189853.jpg\",\n    \"000000306733.jpg\",\n    \"000000021503.jpg\",\n    \"2698119128.jpg\",\n    \"000000490413.jpg\",\n    \"154094533.jpg\",\n    \"2503629305.jpg\",\n    \"000000145591.jpg\",\n    \"2473188198.jpg\",\n    \"000000304365.jpg\",\n    \"2070831281.jpg\",\n]\n\nmetadata = {\n    \"image_paths\": real_filenames,\n    \"num_images\": len(real_filenames),\n    \"dimension\": 512\n}\n\nwith open(\"clip_search_index/metadata.json\", \"w\") as f:\n    json.dump(metadata, f, indent=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:26:01.755176Z","iopub.execute_input":"2026-02-15T14:26:01.755470Z","iopub.status.idle":"2026-02-15T14:26:01.765042Z","shell.execute_reply.started":"2026-02-15T14:26:01.755441Z","shell.execute_reply":"2026-02-15T14:26:01.764532Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import HfApi\napi = HfApi()\napi.upload_file(\n    path_or_fileobj=\"clip_search_index/metadata.json\",\n    path_in_repo=\"clip_search_index/metadata.json\",\n    repo_id=\"Shaheerkhan/clip-faiss-image-search\",\n    repo_type=\"space\",\n    commit_message=\"Fix metadata to match uploaded images\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:26:01.766017Z","iopub.execute_input":"2026-02-15T14:26:01.766323Z","iopub.status.idle":"2026-02-15T14:26:02.933680Z","shell.execute_reply.started":"2026-02-15T14:26:01.766289Z","shell.execute_reply":"2026-02-15T14:26:02.933090Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install boto3\n!pip install boto3\n\nimport boto3\nfrom pathlib import Path\n\n# â”€â”€ CHANGE THESE â”€â”€\nAWS_ACCESS_KEY = \"YOUR KEY\"\nAWS_SECRET_KEY = \"YOUR SECRET KEY\"\nBUCKET_NAME    = \"YOUR BUCKET NAME\"\nPREFIX         = \"images/\"   # optional subfolder\n\ns3 = boto3.client(\n    's3',\n    aws_access_key_id=AWS_ACCESS_KEY,\n    aws_secret_access_key=AWS_SECRET_KEY\n)\n\nlocal_folder = Path(\"images/all\")  # or your folder\n\nfor img_path in local_folder.glob(\"*.jpg\"):\n    key = PREFIX + img_path.name\n    print(f\"Uploading {img_path.name} â†’ {key}\")\n    s3.upload_file(str(img_path), BUCKET_NAME, key)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T14:26:02.934547Z","iopub.execute_input":"2026-02-15T14:26:02.934748Z","execution_failed":"2026-02-15T15:04:55.089Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}